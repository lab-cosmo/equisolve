
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "examples/linear-model.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_examples_linear-model.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_examples_linear-model.py:


Computing a Linear Model
========================

.. start-body

In this tutorial we calculate a linear model using Ridge regression.
If you are never worked with metatensor objects before please take a look at
the documentation.

For constructing a linear Model we need the atomic descriptor as training data
``X`` as well as the energies and forces as target data ``y``.

We first import all necessary packages.

.. GENERATED FROM PYTHON SOURCE LINES 16-26

.. code-block:: default


    import ase.io
    import metatensor
    import numpy as np
    from rascaline import SoapPowerSpectrum

    from equisolve.numpy.models.linear_model import Ridge
    from equisolve.utils.convert import ase_to_tensormap









.. GENERATED FROM PYTHON SOURCE LINES 27-34

Dataset
-------

As data set we use the SHIFTML set. You can obtain the dataset used in this
example from our :download:`website<../../static/dataset.xyz>`.
We read the first 20 structures of the data set using
`ASE <https://wiki.fysik.dtu.dk/ase/>`_.

.. GENERATED FROM PYTHON SOURCE LINES 35-39

.. code-block:: default



    frames = ase.io.read("dataset.xyz", ":20")








.. GENERATED FROM PYTHON SOURCE LINES 40-50

The data set contains everything we need for the model:
The atomic positions we use for the descriptor and with this as
training data. The data set also stores the energies and forces which will be our
target data we regress against.

Training data
-------------

We construct the descriptor training data with a SOAP powerspectrum using
rascaline. We first define the hyper parameters for the calculation

.. GENERATED FROM PYTHON SOURCE LINES 51-69

.. code-block:: default



    HYPER_PARAMETERS = {
        "cutoff": 5.0,
        "max_radial": 6,
        "max_angular": 4,
        "atomic_gaussian_width": 0.3,
        "center_atom_weight": 1.0,
        "radial_basis": {
            "Gto": {},
        },
        "cutoff_function": {
            "ShiftedCosine": {"width": 0.5},
        },
    }

    calculator = SoapPowerSpectrum(**HYPER_PARAMETERS)








.. GENERATED FROM PYTHON SOURCE LINES 70-71

And then run the actual calculation, including gradients with respect to positions.

.. GENERATED FROM PYTHON SOURCE LINES 72-75

.. code-block:: default


    descriptor = calculator.compute(frames, gradients=["positions"])








.. GENERATED FROM PYTHON SOURCE LINES 76-80

For more details on how the descriptor works see the documentation of
rascaline.

We now move all keys into properties to access them for our model.

.. GENERATED FROM PYTHON SOURCE LINES 81-85

.. code-block:: default


    descriptor = descriptor.keys_to_samples("species_center")
    descriptor = descriptor.keys_to_properties(["species_neighbor_1", "species_neighbor_2"])








.. GENERATED FROM PYTHON SOURCE LINES 86-89

The descriptor contains a represenantion with respect to each central atoms per
structure. However, our energies as target data is per structure only.
Therefore, we sum the properties of each center atom per structure.

.. GENERATED FROM PYTHON SOURCE LINES 90-93

.. code-block:: default


    X = metatensor.sum_over_samples(descriptor, ["center", "species_center"])








.. GENERATED FROM PYTHON SOURCE LINES 94-95

The newly defined :class:`metatensor.TensorMap` contains a single block

.. GENERATED FROM PYTHON SOURCE LINES 96-99

.. code-block:: default


    print(f"X contains {len(X.blocks())} block.")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    X contains 1 block.




.. GENERATED FROM PYTHON SOURCE LINES 100-103

As well as 1800 properties and 20 sample.

We acces the data using the :meth:``metatensor.TensorMap.block`` method

.. GENERATED FROM PYTHON SOURCE LINES 104-118

.. code-block:: default



    print(f"X contains {len(X[0].properties)} properties.")
    print(f"X contains {len(X[0].samples)} samples.")

    # Target data
    # -----------
    #
    # We construct the target data by converting energies and forces into a
    # :class:`equisolve.TensorMap`.


    y = ase_to_tensormap(frames, energy="energy", forces="forces")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    X contains 1800 properties.
    X contains 20 samples.




.. GENERATED FROM PYTHON SOURCE LINES 119-120

The target data y contains a single block

.. GENERATED FROM PYTHON SOURCE LINES 121-124

.. code-block:: default


    print(y[0])





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    TensorBlock
        samples (20): ['structure']
        components (): []
        properties (1): ['property']
        gradients: ['positions']




.. GENERATED FROM PYTHON SOURCE LINES 125-130

Construct the model
-------------------

We first initilize the :class:`equisolve.numpy.models.linear_model.Ridge`
object. We automically learn on forces if forces are present.

.. GENERATED FROM PYTHON SOURCE LINES 131-134

.. code-block:: default


    clf = Ridge()








.. GENERATED FROM PYTHON SOURCE LINES 135-141

Before we fit a model we have to define our regulerizer values.

For this we create a TensorMap containing the desired regulerizer values.
Here we chose a regulerizer strength of :math:`1 \cdot 10^-5`. Note that
without standardizing the features and values the regulerizer strength
depends on the system and has to be taken carefully and usually optimized.

.. GENERATED FROM PYTHON SOURCE LINES 142-146

.. code-block:: default


    alpha = metatensor.ones_like(X)
    alpha = metatensor.multiply(alpha, 1e-5)








.. GENERATED FROM PYTHON SOURCE LINES 147-153

So far ``alpha`` contains the same number of samples as ``X``. However,
the regulerizer must only contain a single sample, because all samples will be
regulerized in the same way in a linear model.

We remove all sample except the 0th one by using the
:func:`metatensor.slice`.

.. GENERATED FROM PYTHON SOURCE LINES 154-164

.. code-block:: default


    samples = metatensor.Labels(
        names=["structure"],
        values=np.array([(0,)]),
    )

    alpha = metatensor.slice(alpha, axis="samples", labels=samples)

    print(alpha)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    TensorMap with 1 blocks
    keys: _
          0




.. GENERATED FROM PYTHON SOURCE LINES 165-173

In our regulerizer we use the same values for all properties. However,
:class:`equisolve.numpy.models.linear_model.Ridge` can also handle different
regularization for each property. You can apply a property wise
regularization by setting ``"values"`` of ``alpha`` with an 1d array of the
same length as the number of properties in the training data X (here 7200).

Next we create a sample weighting :class:`equistiore.TensorMap` that weights
energies five times more then the forces.

.. GENERATED FROM PYTHON SOURCE LINES 174-178

.. code-block:: default


    sw = metatensor.ones_like(y)
    sw = metatensor.multiply(sw, 5.0)








.. GENERATED FROM PYTHON SOURCE LINES 179-182

The function `equisolve.utils.dictionary_to_tensormap` create a
:class:`metatensor.TensorMap` with the same shape as our target data ``y`` but
with values a defined by ``sw_dict``.

.. GENERATED FROM PYTHON SOURCE LINES 183-186

.. code-block:: default


    print(sw[0])





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    TensorBlock
        samples (20): ['structure']
        components (): []
        properties (1): ['property']
        gradients: ['positions']




.. GENERATED FROM PYTHON SOURCE LINES 187-189

Finally, we can fit the model using the regulerizer and sample weights as
defined above.

.. GENERATED FROM PYTHON SOURCE LINES 190-193

.. code-block:: default


    clf.fit(X, y, alpha=alpha, sample_weight=sw)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    TorchRidge()



.. GENERATED FROM PYTHON SOURCE LINES 194-196

We now predict values and calculate the root mean squre error
of our model using the ``score`` method.

.. GENERATED FROM PYTHON SOURCE LINES 197-201

.. code-block:: default


    print(f"RMSE energies = {clf.score(X, y, parameter_key='values')[0]:.3f} eV")
    print(f"RMSE forces = {clf.score(X, y, parameter_key='positions')[0]:.3f} eV/Å")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    RMSE energies = 0.105 eV
    RMSE forces = 0.209 eV/Å




.. GENERATED FROM PYTHON SOURCE LINES 202-204

If you only want to predict values you can use the
:meth:`equisolve.numpy.models.linear_model.Ridge.predict` method.

.. GENERATED FROM PYTHON SOURCE LINES 205-207

.. code-block:: default


    clf.predict(X)




.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    TensorMap with 1 blocks
    keys: _
          0




.. _sphx_glr_download_examples_linear-model.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example




    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: linear-model.py <linear-model.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: linear-model.ipynb <linear-model.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
